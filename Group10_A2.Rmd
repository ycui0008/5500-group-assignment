---
title: "Multidimensional Reduction Analysis for Bankrupt Companies"
subtitle: Group 10
author:
  - Yuheng Cui
  - Chenjie Gong
  - Peimin Lin
  - Panagiotis Stylianos
output: 
  bookdown::pdf_document2:
    toc: yes
    toc_depth: '2'
---

\clearpage

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE,
                      fig.align = 'center')
library(tidyverse)
library(visdat)
library(simputation)
library(fastDummies) 
library(MASS)
library(mclust)
library(Rmixmod)
library(DataExplorer) 
library(tidygraph)
library(ggpubr)
library(naniar)
```


```{r read_data}
bankruptcy <- readRDS(here::here("data/Bankruptcy.rds"))
```

# Data description

Data are collected on `r ncol(bankruptcy)` variables each representing different measures of status of `r nrow(bankruptcy)` bankrupt companies in the US. Table \@ref(tab:datadesc) has the detailed variable description.


```{r datadesc}

tibble(
  Variable = c(
    "Name",
    "Assets",
    "CityFiled",
    "CPI",
    "DaysIn",
    "DENYOther",
    "Ebit",
    "Employees",
    "EmplUnion",
    "FilingRate",
    "FirmEnd",
    "GDP",
    "HeadCityPop",
    "HeadCourtCityToDE",
    "HeadStAtFiling",
    "Liab",
    "MonthFiled",
    "PrimeFiling",
    "Sales",
    "SICMajGroup",
    "YearFiled"
  ),
  Decription = c(
    "Name of the firm",
    "Total assets (in millions of dollars)",
    "City where filing took place",
    "U.S CIP at the time of filing",
    "Length of bankruptcy process",
    "CityFiled, categorized as Wilmington (DE), New York (NY) or all other cities (OT)",
    "Earnings (operating income) at time of filing (in millions of dollars)",
    "Number of employees before bankruptcy",
    "Number of union employees before bankruptcy",
    "Total number of other bankrupcy filings in the year of this filing",
    "Short description of the event that ended the firmâ€™s existence",
    "Gross Domestic Product for the Quarter in which the case was filed",
    "The population of the firms headquarters city",
    "The distance in miles from the firms headquarters city to the city in which the case was filed",
    "The state in which firms headquarters is located",
    "Total amount of money owed (in millions of dollars)",
    "Categorical variable where numbers from 1 to 12 correspond to months from Jan to Dec",
    "Prime rate of interest on the bankruptcy filing date",
    "Sales before bankruptcy (in dollars)",
    "Standard industrial clasification code",
    "Year bankruptcy was filed")) %>% 
  knitr::kable(caption = "Variable Description") %>% 
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = F, latex_options = "HOLD_position")
```


Among these variables, `Assets`, `Ebit`, `GDP`, `Liab`, `Employees` and `Sales` are the measures of the status of the companies. `CPI`, `PrimeFiling` and `CityFiled` describe the external environment of the companies. `FirmEnd` tells three different endings of the companies: merged with others, bankruptcy, and continuing the operations.

```{r vismiss, fig.cap = "Missing values in the data set"}
plot_missing(bankruptcy)
```

Figure \@ref(fig:vismiss) shows the missing values in the data set. The most missing values are in `EmplUnion`; fortunately, this variable is not important.


```{r credCheck}
bankruptcy %>% 
  filter(Employees == 1) %>% 
  dplyr::select(Name, Assets, Employees) %>% 
  knitr::kable(caption = "Suspicious Observations") %>% 
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = F,latex_options = "HOLD_position")
```

The data set has some suspicious observations. Table \@ref(tab:credCheck) shows some companies which only have one employee having millions of assets. Therefore, the data set might not be so trustworthy. Further investigation is required.

# Data cleaning 

```{r pairplot, fig.cap = "Overview of all numeric variables in the data set", fig.height=9}
bankruptcy %>% 
  dplyr::select_if(is.numeric) %>% 
  GGally::ggpairs()
```


Figure \@ref(fig:pairplot) shows the relations between any two of the numeric variables in the data set. We can clearly see some outliers in Figure \@ref(fig:pairplot). In addition, we can tell some linear relationship between `Assets` and `Ebit`. For `Sales`, it is difficult to tell any clear relationship with any one of the other variables. We assume that the firms which have similar amounts of assets, EBIT, and liability would have similar sales in the same industry. Therefore, we use `impute_knn()` to impute missing values in `Sales`. Following the same logic, we can impute missing values in `Employees` as well.


## Imputation

```{r}
# impute_lm(bankruptcy, Liab ~ Assets) %>%
#   impute_lm(Ebit ~ Assets) %>%
#   impute_knn(Sales ~ Assets + Ebit + Liab, pool = "univariate", k = 5) %>%
#   impute_knn(Employees ~ Assets + Ebit + Sales, pool = "univariate", k = 5) %>%
#   impute_lm(DaysIn ~ Assets) %>%

bankruptcy %>% 
  separate(SICMajGroup, c("group_code", "group_name"), " ", extra = "merge") %>% 
  mutate(group_code = as.numeric(group_code))-> bankruptcy_imp

bankruptcy_clean <- bankruptcy_imp %>% 
  mutate(group_code = group_code - min(bankruptcy_imp$group_code),
         group_code = as.factor(group_code))

impute_lm(bankruptcy_clean, Liab ~ Assets) %>% 
  impute_lm(Ebit ~ Assets) %>%
  impute_knn(Sales ~ Assets + Ebit + Liab + group_code, pool = "univariate", k = 5) %>% 
  impute_knn(Employees ~ Assets + Ebit + Sales + group_code, pool = "univariate", k = 5) -> bankruptcy_imp
```

```
bankruptcy_imp <- impute_lm(bankruptcy_clean, Liab ~ Assets) %>% # impute `Liab`

  impute_lm(Ebit ~ Assets) %>% # impute `Ebit`
  
  impute_knn(Sales ~ Assets + Ebit + Liab + group_code,
  pool = "univariate", k = 5) %>% # impute `Sales`
  
  impute_knn(Employees ~ Assets + Ebit + Sales + group_code,
  pool = "univariate", k = 5) # impute `Employees`
  
```

`bankruptcy_imp` is the data set after imputation. In Figure \@ref(fig:vismissimp), we can see that all important numeric variables have no missing values.

```{r vismissimp, fig.cap = "Check missing values after imputation"}
plot_missing(bankruptcy)
```





# Factor Analyasis

```{r}
fain <- bankruptcy_imp %>% 
  mutate(Name = abbreviate(Name)) %>% 
  dplyr::select(Assets, CPI, Ebit, Employees, Liab, PrimeFiling, Sales, HeadCityPop) 
```


```{r corCheck}
faout <- fain %>%
  factanal(factors = 3,
           rotation = 'varimax',
           scores = 'Bartlett',
           lower = 0.01)

cor(faout$scores) %>% 
  as.tibble(rownames= NA) %>% 
  knitr::kable(caption = "Check correlation between factors") %>% 
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = F, latex_options = "HOLD_position")
```


We use `varimax` rotation and `Bartlett` score methods for **Factor Analysis**. We tried different numbers of factors, and found 3 factors were the most reasonable. The correlation between factors are all very small (Table \@ref(tab:corCheck)).


```{r}
faout
```

`Factor 1` has high loadings for `Assets` and `Liab`; it is a company's economies of scale factor with higher scores associated with larger scale companies.
`Factor 2` has high loadings for `Sales`; it is a sales factor with higher scores associated with bigger sales.
`Factor 3` has high loadings for `PrimeFiling`; it is the interest rate of borrowing factor with higher score associated with higher borrowing rate.
 

## Limitation of FA

According to the ***Factor Analysis*** output, `HeadCityPop` and `Employees` have very high value of `Uniquenesses` -- 95.9% of `HeadCityPop` cannot be explained by the ***Factor Analysis*** while 73.8% of `Employees` cannot be explained.


# Principal Components Analysis and Biplot

Principal components analysis finds a small number of linear combinations of the orginal variables that explain a large proportion of overall variation in the data. Since the variables in the dataset under investigation are measured in different units we standardise the data by dividing by the standard deviation before conducting the analysis. By selecting two principal components we are able visualise the data using a biplot which is included below

```{r}
pcaout <- bankruptcy_imp %>% 
  mutate(Name = abbreviate(Name)) %>% 
  # column_to_rownames("Name") %>%
  select_if(is.numeric) %>% 
  dplyr::select(Ebit,Assets, CPI, HeadCityPop, Liab, PrimeFiling, Sales) %>%
  prcomp(scale. =TRUE)


```


```{r}
summary(pcaout)
```

Proportion of variance explained by the first five PCs together is 77.62%. Proportion of variance explained by the three PC alone is 15.5%. By Kaisers rule select 3 PCs 

```{r screenplot, fig.cap="Screeplot of PCA"}

screeplot(pcaout,type = 'l')
```

The elbow appears at the three PC, therefore 3 or 4 PCs should be used. Figure \@ref(fig:screeplot))
 

```{r biplot, fig.cap="Biplot produced by PCA"}
p<- biplot(pcaout,scale=0,cex=0.3)

#p+geom_text(check_overlap = TRUE) +geom_text(size = 0.2) +geom_point() + geom_text(hjust = 0, nudge_x = 0.05)
```


The biplot \@ref(fig:biplot)) can be interpreted as follows. The first principal component is a measure of overall company situation since it is positively correlated with variables that indicate a company's bankruptcy, such as cpi, Ebit and GDP . Some values with low values of the first principal component are CDSI, CHVI and AWII. It's all pharmaceutical companies, and the response to the cpi numbers is not that big, because they're all essential elements of life

The biplot also highlights that the B-UC and SthpCrp are outliers, particularly on the first principal component. The first principal component has a high weight of 0.33. Texaco Corporation Texaco Corporation is one of the largest oil companies in the United States and an international oil multinational company with more than 120 subsidiaries and branches. It explores oil in 32 countries, extracts oil in 18 countries, and sells in more than 130 countries. and FRBC is a bank. So these two companies are resource-based companies and banks, both of which are very competitive, so their data may not be very reliable and cannot help us analyze.

```{r removebiplot, fig.cap="Biplot without Outliers"}
pcaoutre <- bankruptcy_imp %>%
  filter(Name!= "First RepublicBank Corp") %>%
  filter(Name!= "Texaco Inc.") %>%
  mutate(Name = abbreviate(Name)) %>% 
  column_to_rownames("Name") %>%
 select_if(is.numeric) %>% 
  dplyr::select(Assets,Ebit, CPI, HeadCityPop, Liab, PrimeFiling, Sales) %>%
  prcomp(scale. =TRUE)
 p1<- biplot(pcaoutre,scale=0,cex=0.3) 

```
\@ref(fig:removebiplot)) From this plot we can more viivd to see the result, because we remove these two outliers, which are First RepublicBank Corp and Texaco Inc.  and we can see primeFliling  has longest line, which means this factor has biggest influence with company.   and  Liabs and Sales are the same way, and the CPI is Completely opposite direction.

# Limitations of the Analysis

Any dimension reduction technique such as principal components analysis represents a loss of information. In this example 0.7762 of the overall variation is explained by the first two principal components and therefore accurately depicted in the biplot. Finally there is some concern that the outliers of FRBC lead to a misleading analysis. 



# Cluster

Why does a company go bankrupt? The biggest reason will be related to their financial position. According to the data, the company's relevant information are Assets, EBIT, Liabilities and Sales. For Assets is a company owned and can provide future economic benefit. Liabilities represent money owed for other parties.



```{r outlier, fig.cap="Overview companies financial positions"}
plot(Ebit ~Liab, bankruptcy)

```

EBIT is an significant index to evaluated the company's operating efficiency. Sales reflect the company's transaction between other parties. Thus, the cluster analysis will focus on company's financial position. Figure \@ref(fig:outlier) shows the EBIT and liabilities of companies, most companies' EBIT are less than liabilities and even in negativewhich means they did not have ability to pay the debt which caused bankruptcy in the end. The company `First RepublicBank Corp` and `Texaco Inc.` have large amount of liabilities than other companies and for better clustering, we will consider them as outliers and remove them. 
As variable `Sales` amounts are larger than other financial positions, we have to normalize them before calculating the distance.

As variable `Sales` amounts are larger than other financial positions, we have to normalize them before calculating the distance.


```{r tidydata}
tidy <- bankruptcy_imp %>% 
  dplyr::select(-EmplUnion) %>%

  dplyr::select(Assets, Ebit, Liab, Sales, PrimeFiling) %>% 
  filter(Liab < 40000)


```


```{r gaussian}
all <- mixmodCluster(tidy, 4:10)
all

```

As the data is multidimensional, we use Gaussian Mixture model tofit the data. 
Comparing the BIC, we can find that clusters of 8 are the best cluster group numbers.

```{r multi}
m <- apply(tidy, 2, mean)
s <- apply(tidy, 2, sd)
z<- scale(tidy, m,s)
d<- z %>% #scale data
dist(method = 'euclidean') #compute distance matrix
hcl <- hclust(d,method='ward.D2')
```


Then, we are also using Ward method, average method, centroid method and complete method to check the rand index. The rand index of ward's method with average method is 0.15, with centroid method is 0.1 and with complete method is 0.29. Though, the rand index is low, complete method has a relatively high level of agreement with Ward's method.


```{r mul}

com_f_ward<- cutree(hcl,k = 8)

com_f_al <- hclust(d,method='average')%>%
cutree(k = 8)

com_f_cm <- hclust(d,method='centroid')%>%
cutree(k = 8)

com_f_cl <- hclust(d,method='complete')%>%
cutree(k = 8)

```


```{r rand}
wardal <- adjustedRandIndex(com_f_ward,com_f_al)
wardcm <- adjustedRandIndex(com_f_ward,com_f_cm)
wardcl <- adjustedRandIndex(com_f_ward,com_f_cl)
```

```{r aggre}
aggregate(z, list(com_f_ward), mean) %>%
  knitr::kable(caption = "Mean of each clusters") %>% 
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = F, latex_options = "HOLD_position")
```

 Table \@ref(tab:aggre) shows the mean of each cluster, cluster 4 has the highest average assets and liabilities, however, their EBIT are not the best and prime rate of interest's average are negative. Cluster 3 has the highest average EBIT, but their average sales are low. Overview, the cluster can find that the bankruptcy companies always arise some issues in their financial position that caused their companies went into filling. 


# Multidimensional Scaling

For this part the focus was on finding a 2D representation of the data that accurately depicts the distance of the observations in the higher dimensions. The main concerns was how to combine both the numeric and the categorical variables in the dataset when calculating the distance metric, along with which variables to select that provide a high goodness of fit measure for the multidimensional scaling providing at the same time that these subset of variables doesn't alter the structure of the observations in the higher dimensional space.

Furthermore, we were also curious to see if the clusters found in the previous section could
also be identified in the 2D representation of the multidimensional scaling.

Classical multidimensional scaling was used, as there was no indication from the initial exploratory analysis that the relationship between some observations was non-linear.



```{r}
bankruptcy_imp <- bankruptcy_imp %>%   # add cluster groups to the dataset
  filter(Liab < 40000) %>% 
  mutate(
    cluster_group = as.factor(com_f_cl)
  )

# some further imputations

bankruptcy_imp$DaysIn <- impute_mean(bankruptcy_imp$DaysIn) 
bankruptcy_imp$HeadCourtCityToDE <- impute_mean(bankruptcy_imp$HeadCourtCityToDE)

bankruptcy_imp <- bankruptcy_imp %>%
  mutate(EmplUnion = as.double(EmplUnion)) %>% 
  impute_lm(EmplUnion ~ (Employees + Sales + DENYOther) )
```


The distance metric used in the analysis was the sum of the Euclidean distances between the numeric variables and the Jaccard distance between the non-numeric variables for each observation. To calculate the latter, all character variables were transformed to dummy variables (0, 1).



```{r}
bank_cat <- bankruptcy_imp %>% 
  filter(Liab < 40000) %>%  
  select_if(is.character)

# creating dummy variables

bank_cat <- dummy_cols(bank_cat, select_columns = 'CityFiled') 
bank_cat <- dummy_cols(bank_cat, select_columns = 'DENYOther')
bank_cat <- dummy_cols(bank_cat, select_columns = 'HeadStAtFiling')
bank_cat <- dummy_cols(bank_cat, select_columns = 'group_name')
bank_cat <- dummy_cols(bank_cat, select_columns = 'FirmEnd')

# distance of binary dummy variables

bank_cat %>% 
  select_if(is.numeric) %>% #Only metric data
  scale() %>% 
  dist(method = "binary")->delta #Distance

# distance of numeric variables

bankruptcy_imp %>% 
  filter(Liab < 40000) %>% 
  select_if(is.numeric)%>% #Only metric data
  dplyr::select(Assets, Ebit, Liab, Sales, PrimeFiling) %>% 
  scale%>% #Standardise
  dist()->delta2 #Distance

# sum of distances

both_delta <- delta + delta2
```

```{r gof}
bankruptcy_imp %>% 
  filter(Liab < 40000) %>% 
  pull(Name)%>% 
  abbreviate()-> 
  attributes(both_delta)$Labels 



mdsout<-cmdscale(both_delta, eig=TRUE)
 

mdsout$GOF %>% 
  knitr::kable(caption = "Goodnes of Fit Measures", col.names = "Value") %>% 
  kableExtra::kable_styling(latex_options = "HOLD_position")
```

Table \@ref(tab:gof) suggests that selecting a subset of the numeric variables that represent the financial health status of the company alongside with the character variables, such as location and industry yields a respectable value for the metrics, indicating a trustworthy multidimensional scaling.     

```{r mds, fig.cap="Multidimensional Scaling 2D representation"}

mdsout$points%>%
  as.data.frame()%>%
  tibble::rownames_to_column(var = 'BankName')->df


df<-add_column(df,Manufacturer=bankruptcy_imp %>% filter(Liab < 40000) %>% dplyr::select(cluster_group)) 

ggplot(df ,aes(x=V1,y=V2,col= Manufacturer$cluster_group, label=`BankName`)) +
  geom_text(size=2) +
  theme_classic() +
  labs(
    color = "Cluster Group",
    title = "MDS"
  )

```

Figure \@ref(fig:mds) indicates that the result of the multidimensional scaling is consistent with the clustering results, as the 2D representation of the companies follows a clear structure with easily identifiable clusters, especially for those with a lot of observations.





\clearpage





# APPENDIX

```{r hist, echo=FALSE}
plot_histogram(bankruptcy)
```

In the above plot we see that there are no as such obvious outliers. Thus, there is no need to cap outliers from this data set. 

 Also, an observation regarding the data is that, most of the variables showing histogram are **left Skewed** this is because the mean is greater than the median. In this case because skewed-right or left data have a few large values that drive the mean upward but do not affect where the exact middle of the data is (that is, the median).
 
```{r}
summary(bankruptcy)
```


- Skimming function is use to check the data quality. It gives an overview of the data frame including number of rows and column, column types and if data frame is grouped. Initially we have:

1. **Data Summary**: There are **436** number of rows and **21** number of columns.

2. **Column type frequency**: In this data there total three types of variable viz. **Character**, **Interger**, and **Numeric**. The maximum missing values are seen in **NUmeric**

3. **Central tendency for all the variables**: The central tendency provides us with the information of **Mean, Standard deviation, Percentile, and Range.** 



