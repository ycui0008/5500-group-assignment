---
title: ""
author: "Group 10"
output: 
  bookdown::pdf_document2:
    toc: yes
    toc_depth: '2'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE,
                      fig.align = 'center')
library(tidyverse)
library(visdat)
library(simputation)
library(fastDummies) # does not work for multi-level factors?
library(MASS)
library(mclust)
library(Rmixmod)
library(DataExplorer) 
library(tidygraph)
library(ggpubr)
```


```{r read_data}
bankruptcy <- readRDS(here::here("data/Bankruptcy.rds"))
```

# Data description

Data are collected on `r ncol(bankruptcy)` variables each representing different measures of status of `r nrow(bankruptcy)` bankrupt companies in the US. Table \@ref(tab:datadesc) has the detailed variable description.


```{r datadesc}
tibble(
  Variable = c(
    "Name",
    "Assets",
    "CityFiled",
    "CPI",
    "DaysIn",
    "DENYOther",
    "Ebit",
    "Employees",
    "EmplUnion",
    "FilingRate",
    "FirmEnd",
    "GDP",
    "HeadCityPop",
    "HeadCourtCityToDE",
    "HeadStAtFiling",
    "Liab",
    "MonthFiled",
    "PrimeFiling",
    "Sales",
    "SICMajGroup",
    "YearFiled"
  ),
  Decription = c(
    "Name of the firm",
    "Total assets (in millions of dollars)",
    "City where filing took place",
    "U.S CIP at the time of filing",
    "Length of bankruptcy process",
    "CityFiled, categorized as Wilmington (DE), New York (NY) or all other cities (OT)",
    "Earnings (operating income) at time of filing (in millions of dollars)",
    "Number of employees before bankruptcy",
    "Number of union employees before bankruptcy",
    "Total number of other bankrupcy filings in the year of this filing",
    "Short description of the event that ended the firmâ€™s existence",
    "Gross Domestic Product for the Quarter in which the case was filed",
    "The population of the firms headquarters city",
    "The distance in miles from the firms headquarters city to the city in which the case was filed",
    "The state in which firms headquarters is located",
    "Total amount of money owed (in millions of dollars)",
    "Categorical variable where numbers from 1 to 12 correspond to months from Jan to Dec",
    "Prime rate of interest on the bankruptcy filing date",
    "Sales before bankruptcy (in dollars)",
    "Standard industrial clasification code",
    "Year bankruptcy was filed")) %>% 
  knitr::kable(caption = "Variable Description") %>% 
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = F)
```


Among these variables, `Assets`, `Ebit`, `GDP`, `Liab`, `Employees` and `Sales` are the measures of the status of the companies. `CPI`, `PrimeFiling` and `CityFiled` describe the external environment of the companies. `FirmEnd` tells three different endings of the companies: merged with others, bankruptcy, and continuing the operations.

```{r vismiss, fig.cap = "Missing values in the data set"}
plot_missing(bankruptcy)
```

Figure \@ref(fig:vismiss) shows the missing values in the data set. The most missing values are in `EmplUnion`; fortunately, this variable is not important.


```{r credCheck}
bankruptcy %>% 
  filter(Employees == 1) %>% 
  dplyr::select(Name, Assets, Employees) %>% 
  knitr::kable(caption = "Suspicious Observations") %>% 
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = F)
```

The data set has some suspicious observations. Table \@ref(tab:credCheck) shows some companies which only have one employee having millions of assets. Therefore, the data set might not be so trustworthy. Further investigation is required.

# Data cleaning 

```{r pairplot, fig.cap = "Overview of all numeric variables in the data set"}
bankruptcy %>% 
  dplyr::select_if(is.numeric) %>% 
  GGally::ggpairs()
```


Figure \@ref(fig:pairplot) shows the relations between any two of the numeric variables in the data set. We can clearly see some outliers in Figure \@ref(fig:pairplot). In addition, we can tell some linear relationship between `Assets` and `Ebit`. For `Sales`, it is difficult to tell any clear relationship with any one of the other variables. We assume that the firms which have similar amounts of assets, EBIT, and liability would have similar sales in the same industry. Therefore, we use `impute_knn()` to impute missing values in `Sales`. Following the same logic, we can impute missing values in `Employees` as well.


## Imputation

```{r}
# impute_lm(bankruptcy, Liab ~ Assets) %>%
#   impute_lm(Ebit ~ Assets) %>%
#   impute_knn(Sales ~ Assets + Ebit + Liab, pool = "univariate", k = 5) %>%
#   impute_knn(Employees ~ Assets + Ebit + Sales, pool = "univariate", k = 5) %>%
#   impute_lm(DaysIn ~ Assets) %>%

bankruptcy %>% 
  separate(SICMajGroup, c("group_code", "group_name"), " ", extra = "merge") %>% 
  mutate(group_code = as.numeric(group_code))-> bankruptcy_imp

bankruptcy_clean <- bankruptcy_imp %>% 
  mutate(group_code = group_code - min(bankruptcy_imp$group_code),
         group_code = as.factor(group_code))

impute_lm(bankruptcy_clean, Liab ~ Assets) %>% 
  impute_lm(Ebit ~ Assets) %>%
  impute_knn(Sales ~ Assets + Ebit + Liab + group_code, pool = "univariate", k = 5) %>% 
  impute_knn(Employees ~ Assets + Ebit + Sales + group_code, pool = "univariate", k = 5) -> bankruptcy_imp
```

```
bankruptcy_imp <- impute_lm(bankruptcy_clean, Liab ~ Assets) %>% # impute `Liab`

  impute_lm(Ebit ~ Assets) %>% # impute `Ebit`
  
  impute_knn(Sales ~ Assets + Ebit + Liab + group_code,
  pool = "univariate", k = 5) %>% # impute `Sales`
  
  impute_knn(Employees ~ Assets + Ebit + Sales + group_code,
  pool = "univariate", k = 5) # impute `Employees`
  
```

`bankruptcy_imp` is the data set after imputation. In Figure \@ref(fig:vismissimp), we can see that all important numeric variables have no missing values.

```{r vismissimp, fig.cap = "Check missing values after imputation"}
plot_missing(bankruptcy)
```





# Factor Analyasis

```{r}
fain <- bankruptcy_imp %>% 
  mutate(Name = abbreviate(Name)) %>% 
  dplyr::select(Assets, CPI, Ebit, Employees, Liab, PrimeFiling, Sales, HeadCityPop) 
```


```{r corCheck}
faout <- fain %>%
  factanal(factors = 3,
           rotation = 'varimax',
           scores = 'Bartlett',
           lower = 0.01)

cor(faout$scores) %>% 
  as.tibble(rownames= NA) %>% 
  knitr::kable(caption = "Check correlation between factors") %>% 
  kableExtra::kable_styling(bootstrap_options = "striped", full_width = F)
```


We use `varimax` rotation and `Bartlett` score methods for **Factor Analysis**. We tried different numbers of factors, and found 3 factors were the most reasonable. The correlation between factors are all very small (Table \@ref(tab:corCheck)).


```{r}
faout
```

`Factor 1` has high loadings for `Assets` and `Liab`; it is a company's economies of scale factor with higher scores associated with larger scale companies.
`Factor 2` has high loadings for `Sales`; it is a sales factor with higher scores associated with bigger sales.
`Factor 3` has high loadings for `PrimeFiling`; it is the interest rate of borrowing factor with higher score associated with higher borrowing rate.
 

## Limitation of FA

According to the ***Factor Analysis*** output, `HeadCityPop` and `Employees` have very high value of `Uniquenesses` -- 95.9% of `HeadCityPop` cannot be explained by the ***Factor Analysis*** while 73.8% of `Employees` cannot be explained.


# Principal Components Analysis and Biplot

Principal components analysis finds a small number of linear combinations of the orginal variables that explain a large proportion of overall variation in the data. Since the variables in the dataset under investigation are measured in different units we standardise the data by dividing by the standard deviation before conducting the analysis. By selecting two principal components we are able visualise the data using a biplot which is included below

```{r}
pcaout <- bankruptcy_imp %>% 
  mutate(Name = abbreviate(Name)) %>% 
  column_to_rownames("Name") %>%
  select_if(is.numeric) %>% 
  dplyr::select(Ebit,Assets, CPI, HeadCityPop, Liab, PrimeFiling, Sales) %>%
  prcomp(scale. =TRUE)


```


```{r}
summary(pcaout)
```

### Proportion of variance explained by the first five PCs together is 77.62%
### Proportion of variance explained by the three PC alone is 15.5%
### By Kaisers rule select 3 PCs 

```{r screenplot}

screeplot(pcaout,type = 'l')
```

The elbow appears at the three PC, therefore 3 or 4 PCs should be used.\@ref(fig:screeplot))
 

```{r biplot}
p<- biplot(pcaout,scale=0,cex=0.3)

#p+geom_text(check_overlap = TRUE) +geom_text(size = 0.2) +geom_point() + geom_text(hjust = 0, nudge_x = 0.05)
```


The biplot \@ref(fig:biplot)) can be interpreted as follows. The first principal component is a measure of overall company situation since it is positively correlated with variables that indicate a company's bankruptcy, such as cpi, Ebit and GDP . Some values with low values of the first principal component are CDSI, CHVI and AWII. It's all pharmaceutical companies, and the response to the cpi numbers is not that big, because they're all essential elements of life

The biplot also highlights that the B-UC and SthpCrp are outliers, particularly on the first principal component. The first principal component has a high weight of 0.33. Texaco Corporation Texaco Corporation is one of the largest oil companies in the United States and an international oil multinational company with more than 120 subsidiaries and branches. It explores oil in 32 countries, extracts oil in 18 countries, and sells in more than 130 countries. and FRBC is a bank. So these two companies are resource-based companies and banks, both of which are very competitive, so their data may not be very reliable and cannot help us analyze.

```{r removebiplot}
pcaoutre <- bankruptcy_imp %>%
  filter(Name!= "First RepublicBank Corp") %>%
  filter(Name!= "Texaco Inc.") %>%
  mutate(Name = abbreviate(Name)) %>% 
  column_to_rownames("Name") %>%
 select_if(is.numeric) %>% 
  dplyr::select(Assets,Ebit, CPI, HeadCityPop, Liab, PrimeFiling, Sales) %>%
  prcomp(scale. =TRUE)
 p1<- biplot(pcaoutre,scale=0,cex=0.3) 

```
\@ref(fig:removebiplot)) From this plot we can more viivd to see the result, because we remove these two outliers, which are First RepublicBank Corp and Texaco Inc.  and we can see primeFliling  has longest line, which means this factor has biggest influence with company.   and  Liabs and Sales are the same way, and the CPI is Completely opposite direction.

# Limitations of the Analysis

Any dimension reduction technique such as principal components analysis represents a loss of information. In this example 0.7762 of the overall variation is explained by the first two principal components and therefore accurately depicted in the biplot. Finally there is some concern that the outliers of FRBC lead to a misleading analysis. 



# Cluster

Why does a company go bankrupt? The biggest reason will be related to their financial position. According to the data, the company's  relevant information are Assets, EBIT, Liabilities and Sales. For Assets is a company owned and can provide future economic benefit. Liabilities represent money owed for other parties.

EBIT is an significant index to evaluated the company's operating efficiency. Sales reflect the company's transaction between other parties. Thus, the cluster analysis will focus on company's financial position. Figure \@ref(fig:outlier) shows the EBIT and liabilities of companies,  most companies' EBIT are less than liabilities and even in negative which means they did not have ability to pay the debt which caused bankruptcy in the end. There is one company have large amount of liabilities than other companies and for better clustering, we will consider it as an outlier and not use in cluster analysis. 
 

```{r outlier, fig.cap="Overview companies financial positions"}
plot(Ebit ~Liab, bankruptcy)

```

As variable `Sales` amounts are larger than other financial positions, we have to normalize them before calculating the distance.


```{r}
tidy <- bankruptcy_imp %>% 
  dplyr::select(-EmplUnion) %>%

  dplyr::select(Assets, Ebit, Liab, Sales, PrimeFiling) %>% 
  filter(Liab < 40000)

m <- apply(tidy, 2, mean)
s <- apply(tidy, 2, sd)
z<- scale(tidy, m,s)
```



```{r multi}
d<- z %>% #scale data
dist(method = 'euclidean') #compute distance matrix
hcl <- hclust(d,method='ward.D2')

```


```{r}
all <- mixmodCluster(tidy, 4:10)
all


```

Comparing the BIC, we can find that clusters of 5 are the best cluster group numbers. Then, we are using Ward method, average method, centroid method and complete method and use Average linkage has a relatively high level of agreement with Ward's method.


```{r mul}

com_f_ward<- cutree(hcl,k = 7)

com_f_al <- hclust(d,method='average')%>%
cutree(k = 7)

com_f_cm <- hclust(d,method='centroid')%>%
cutree(k = 7)

com_f_cl <- hclust(d,method='complete')%>%
cutree(k = 7)

```


```{r rand}

adjustedRandIndex(com_f_ward,com_f_al)
adjustedRandIndex(com_f_ward,com_f_cm)
adjustedRandIndex(com_f_ward,com_f_cl)

```


```{r}
aggregate(z, list(com_f_ward), mean)
```












# APPENDIX

```{r hist, echo=FALSE}
plot_histogram(bankruptcy)
```

In the above plot we see that there are no as such obvious outliers. Thus, there is no need to cap outliers from this data set. 

 Also, an observation regarding the data is that, most of the variables showing histogram are **left Skewed** this is because the mean is greater than the median. In this case because skewed-right or left data have a few large values that drive the mean upward but do not affect where the exact middle of the data is (that is, the median).
 
```{r}
skimr::skim(bankruptcy)
```


- Skimming function is use to check the data quality. It gives an overview of the data frame including number of rows and column, column types and if data frame is grouped. Initially we have:

1. **Data Summary**: There are **436** number of rows and **21** number of columns.

2. **Column type frequency**: In this data there total three types of variable viz. **Character**, **Interger**, and **Numeric**. The maximum missing values are seen in **NUmeric**

3. **Central tendency for all the variables**: The central tendency provides us with the information of **Mean, Standard deviation, Percentile, and Range.** 



